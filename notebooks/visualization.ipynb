{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QS-lq6cHRfhl"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# --- 1. Setup: Clone Repository and Install Dependencies ---\n",
        "#\n",
        "print(\"--- Step 1: Cloning repository and installing project... ---\")\n",
        "!git clone https://github.com/DanielBerns/weather_forecast_at_the_cloud.git\n",
        "%cd weather_forecast_at_the_cloud\n",
        "# Install the project and its dependencies\n",
        "!pip install .\n",
        "print(\"--- Setup complete. ---\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# --- 2. Configuration: Create Directories and config.yaml ---\n",
        "#\n",
        "import os\n",
        "import yaml\n",
        "\n",
        "print(\"--- Step 2: Creating directories and default config.yaml... ---\")\n",
        "# Create directories for processed data and models\n",
        "os.makedirs(\"processed_data\", exist_ok=True)\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "\n",
        "# Define the default configuration\n",
        "# This is based on the config.yaml you provided.\n",
        "# If your model or data uses different parameters, you can edit this cell.\n",
        "config_data = {\n",
        "    'model_name': 'LSTM',  # IMPORTANT: Change this to your model ('Linear', 'Dense', 'CNN', or 'LSTM')\n",
        "    'epochs_per_session': 10,\n",
        "    'sessions': 3,\n",
        "    'patience': 3,\n",
        "    'out_steps': 24,       # IMPORTANT: Must match your trained model\n",
        "    'input_width': 24,     # IMPORTANT: Must match your trained model\n",
        "    'conv_width': 3,\n",
        "    'label_column': 'temperature_celsius', # IMPORTANT: Must match your trained model\n",
        "    'raw_data_path': './raw_data',\n",
        "    'processed_data_path': './processed_data',\n",
        "    'models_path': './models',\n",
        "    'results_path': './results',\n",
        "    'logs_path': './logs',\n",
        "    'gdrive_path': '/content/drive/MyDrive/weather_forecast_at_the_cloud',\n",
        "}\n",
        "\n",
        "# Write the configuration to config.yaml\n",
        "config_path = \"config.yaml\"\n",
        "with open(config_path, \"w\") as f:\n",
        "    yaml.dump(config_data, f)\n",
        "\n",
        "print(f\"Created directories and default {config_path}.\")\n",
        "print(\"Please EDIT the 'model_name' in the cell above if it's not 'LSTM'.\")"
      ],
      "metadata": {
        "id": "2wWomtLGRhLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# --- 3. Upload Files ---\n",
        "#\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "print(\"--- Step 3: Upload your files... ---\")\n",
        "\n",
        "# --- Upload test.csv ---\n",
        "print(\"\\n[Action] Please upload your processed 'test.csv' file:\")\n",
        "uploaded_files = files.upload()\n",
        "if 'test.csv' in uploaded_files:\n",
        "    shutil.move('test.csv', 'processed_data/test.csv')\n",
        "    print(\"Moved 'test.csv' to 'processed_data/test.csv'\")\n",
        "else:\n",
        "    print(\"ERROR: 'test.csv' not found in upload. Please re-run this cell.\")\n",
        "\n",
        "# --- Upload model files ---\n",
        "print(\"\\n[Action] Please upload your trained model files (e.g., 'LSTM.keras' and 'LSTM.json'):\")\n",
        "# We read the model name from the config to prompt the user\n",
        "model_name = config_data.get('model_name', 'LSTM')\n",
        "print(f\"Expecting '{model_name}.keras' and '{model_name}.json'\")\n",
        "uploaded_model_files = files.upload()\n",
        "\n",
        "# Move the uploaded model files\n",
        "moved_model_files = False\n",
        "for filename in uploaded_model_files.keys():\n",
        "    if filename.endswith(('.keras', '.json')):\n",
        "        shutil.move(filename, f'models/{filename}')\n",
        "        print(f\"Moved '{filename}' to 'models/{filename}'\")\n",
        "        moved_model_files = True\n",
        "\n",
        "if not moved_model_files:\n",
        "    print(\"ERROR: No model files (.keras or .json) found. Please re-run this cell.\")\n",
        "\n",
        "print(\"\\n--- File upload complete. Verifying... ---\")\n",
        "!ls -l ./processed_data\n",
        "!ls -l ./models"
      ],
      "metadata": {
        "id": "o5veFu4IRu0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# --- 4. Load Model, Data, and Visualize Predictions ---\n",
        "#\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "# Import the necessary classes from your project's source code\n",
        "from weather_forecast_at_the_cloud.utils.window_generator import WindowGenerator\n",
        "from weather_forecast_at_the_cloud.models.linear_weather_forecast import LinearWeatherForecast\n",
        "from weather_forecast_at_the_cloud.models.dense_weather_forecast import DenseWeatherForecast\n",
        "from weather_forecast_at_the_cloud.models.cnn_weather_forecast import CNNWeatherForecast\n",
        "from weather_forecast_at_the_cloud.models.rnn_weather_forecast import RNNWeatherForecast\n",
        "\n",
        "print(\"--- Step 4: Loading model and data for visualization... ---\")\n",
        "\n",
        "# --- 1. Load Config (already done in Cell 2, just reading it) ---\n",
        "with open(config_path, \"r\") as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "model_name = config['model_name']\n",
        "print(f\"Loaded configuration for model: {model_name}\")\n",
        "\n",
        "# --- 2. Load the Trained Model ---\n",
        "# This dictionary maps model names to their respective classes\n",
        "models = {\n",
        "    \"Linear\": LinearWeatherForecast,\n",
        "    \"Dense\": DenseWeatherForecast,\n",
        "    \"CNN\": CNNWeatherForecast,\n",
        "    \"LSTM\": RNNWeatherForecast,\n",
        "}\n",
        "\n",
        "model_class = models.get(model_name)\n",
        "if model_class is None:\n",
        "    print(f\"ERROR: Unknown model name: {model_name}\")\n",
        "else:\n",
        "    # Base path for the model (e.g., './models/LSTM')\n",
        "    model_base_path = Path(config['models_path']) / model_name\n",
        "\n",
        "    print(f\"Loading model from {model_base_path}...\")\n",
        "    # The .load() classmethod (from models/utils.py) handles suffixes\n",
        "    try:\n",
        "        model_wrapper = model_class.load(model_base_path)\n",
        "        print(\"Model loaded successfully.\")\n",
        "\n",
        "        # --- 3. Load Test Data ---\n",
        "        processed_data_path = Path(config['processed_data_path'])\n",
        "        test_df_path = processed_data_path / 'test.csv'\n",
        "\n",
        "        if not test_df_path.exists():\n",
        "            print(f\"ERROR: 'test.csv' not found at {test_df_path}\")\n",
        "        else:\n",
        "            test_df = pd.read_csv(test_df_path, index_col='timestamp')\n",
        "            # Ensure index is datetime for time-series plotting\n",
        "            test_df.index = pd.to_datetime(test_df.index)\n",
        "            print(\"Test data loaded.\")\n",
        "\n",
        "            # --- 4. Create Window Generator ---\n",
        "            # A dummy DataFrame is needed to initialize the generator\n",
        "            # since we only care about the .test property\n",
        "            dummy_df = pd.DataFrame(columns=test_df.columns)\n",
        "\n",
        "            test_window = WindowGenerator(\n",
        "                input_width=config['input_width'],\n",
        "                label_width=config['out_steps'],\n",
        "                shift=config['out_steps'],\n",
        "                train_df=dummy_df,  # Not needed for plotting\n",
        "                val_df=dummy_df,    # Not needed for plotting\n",
        "                test_df=test_df,\n",
        "                label_columns=[config['label_column']]\n",
        "            )\n",
        "\n",
        "            print(\"WindowGenerator created for test data:\")\n",
        "            print(test_window)\n",
        "\n",
        "            # --- 5. Plot Predictions vs. Actuals ---\n",
        "            plot_column = config['label_column']\n",
        "            print(f\"\\nGenerating plot for column: {plot_column}...\")\n",
        "\n",
        "            # Use the WindowGenerator's built-in plot method\n",
        "            # It shows Inputs (blue), Actuals (green), and Predictions (orange)\n",
        "            # We pass `model_wrapper.model` which is the actual Keras model\n",
        "            test_window.plot(model_wrapper.model, plot_col=plot_column)\n",
        "            plt.show()\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"\\n--- ERROR ---\")\n",
        "        print(f\"Could not find model files at '{model_base_path}'.\")\n",
        "        print(f\"Please make sure '{model_name}.keras' and '{model_name}.json' are in the 'models' folder.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn error occurred: {e}\")"
      ],
      "metadata": {
        "id": "D3dHB0pxR3w4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}